{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_val = '?'\n",
    "df = pd.read_csv('adult.csv',na_values = missing_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18        NaN  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                NaN    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass  fnlwgt   education  educational-num  \\\n",
       "48837   27       Private  257302  Assoc-acdm               12   \n",
       "48838   40       Private  154374     HS-grad                9   \n",
       "48839   58       Private  151910     HS-grad                9   \n",
       "48840   22       Private  201490     HS-grad                9   \n",
       "48841   52  Self-emp-inc  287927     HS-grad                9   \n",
       "\n",
       "           marital-status         occupation relationship   race  gender  \\\n",
       "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
       "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
       "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
       "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
       "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "48837             0             0              38  United-States  <=50K  \n",
       "48838             0             0              40  United-States   >50K  \n",
       "48839             0             0              40  United-States  <=50K  \n",
       "48840             0             0              20  United-States  <=50K  \n",
       "48841         15024             0              40  United-States   >50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48842, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       "workclass          2799\n",
       "fnlwgt                0\n",
       "education             0\n",
       "educational-num       0\n",
       "marital-status        0\n",
       "occupation         2809\n",
       "relationship          0\n",
       "race                  0\n",
       "gender                0\n",
       "capital-gain          0\n",
       "capital-loss          0\n",
       "hours-per-week        0\n",
       "native-country      857\n",
       "income                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "workclass          0\n",
       "fnlwgt             0\n",
       "education          0\n",
       "educational-num    0\n",
       "marital-status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "gender             0\n",
       "capital-gain       0\n",
       "capital-loss       0\n",
       "hours-per-week     0\n",
       "native-country     0\n",
       "income             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no missing value containg in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass     education  educational-num      marital-status  \\\n",
       "0   25    Private          11th                7       Never-married   \n",
       "1   38    Private       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  Some-college               10  Married-civ-spouse   \n",
       "5   34    Private          10th                6       Never-married   \n",
       "\n",
       "          occupation   relationship   race gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct      Own-child  Black   Male             0             0   \n",
       "1    Farming-fishing        Husband  White   Male             0             0   \n",
       "2    Protective-serv        Husband  White   Male             0             0   \n",
       "3  Machine-op-inspct        Husband  Black   Male          7688             0   \n",
       "5      Other-service  Not-in-family  White   Male             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "5              30  United-States  <=50K  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('fnlwgt',axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'fnlwgt' dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          workclass     education      marital-status         occupation  \\\n",
       "0           Private          11th       Never-married  Machine-op-inspct   \n",
       "1           Private       HS-grad  Married-civ-spouse    Farming-fishing   \n",
       "2         Local-gov    Assoc-acdm  Married-civ-spouse    Protective-serv   \n",
       "3           Private  Some-college  Married-civ-spouse  Machine-op-inspct   \n",
       "5           Private          10th       Never-married      Other-service   \n",
       "...             ...           ...                 ...                ...   \n",
       "48837       Private    Assoc-acdm  Married-civ-spouse       Tech-support   \n",
       "48838       Private       HS-grad  Married-civ-spouse  Machine-op-inspct   \n",
       "48839       Private       HS-grad             Widowed       Adm-clerical   \n",
       "48840       Private       HS-grad       Never-married       Adm-clerical   \n",
       "48841  Self-emp-inc       HS-grad  Married-civ-spouse    Exec-managerial   \n",
       "\n",
       "        relationship   race  gender native-country income  \n",
       "0          Own-child  Black    Male  United-States  <=50K  \n",
       "1            Husband  White    Male  United-States  <=50K  \n",
       "2            Husband  White    Male  United-States   >50K  \n",
       "3            Husband  Black    Male  United-States   >50K  \n",
       "5      Not-in-family  White    Male  United-States  <=50K  \n",
       "...              ...    ...     ...            ...    ...  \n",
       "48837           Wife  White  Female  United-States  <=50K  \n",
       "48838        Husband  White    Male  United-States   >50K  \n",
       "48839      Unmarried  White  Female  United-States  <=50K  \n",
       "48840      Own-child  White    Male  United-States  <=50K  \n",
       "48841           Wife  White  Female  United-States   >50K  \n",
       "\n",
       "[45222 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "cat_df = pd.DataFrame(encoder.fit_transform(cat), \n",
    "                      columns=encoder.get_feature_names(cat.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>workclass_Without-pay</th>\n",
       "      <th>education_11th</th>\n",
       "      <th>education_12th</th>\n",
       "      <th>education_1st-4th</th>\n",
       "      <th>education_5th-6th</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45217</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45218</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45219</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45221</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass_Local-gov  workclass_Private  workclass_Self-emp-inc  \\\n",
       "0                      0.0                1.0                     0.0   \n",
       "1                      0.0                1.0                     0.0   \n",
       "2                      1.0                0.0                     0.0   \n",
       "3                      0.0                1.0                     0.0   \n",
       "4                      0.0                1.0                     0.0   \n",
       "...                    ...                ...                     ...   \n",
       "45217                  0.0                1.0                     0.0   \n",
       "45218                  0.0                1.0                     0.0   \n",
       "45219                  0.0                1.0                     0.0   \n",
       "45220                  0.0                1.0                     0.0   \n",
       "45221                  0.0                0.0                     1.0   \n",
       "\n",
       "       workclass_Self-emp-not-inc  workclass_State-gov  workclass_Without-pay  \\\n",
       "0                             0.0                  0.0                    0.0   \n",
       "1                             0.0                  0.0                    0.0   \n",
       "2                             0.0                  0.0                    0.0   \n",
       "3                             0.0                  0.0                    0.0   \n",
       "4                             0.0                  0.0                    0.0   \n",
       "...                           ...                  ...                    ...   \n",
       "45217                         0.0                  0.0                    0.0   \n",
       "45218                         0.0                  0.0                    0.0   \n",
       "45219                         0.0                  0.0                    0.0   \n",
       "45220                         0.0                  0.0                    0.0   \n",
       "45221                         0.0                  0.0                    0.0   \n",
       "\n",
       "       education_11th  education_12th  education_1st-4th  education_5th-6th  \\\n",
       "0                 1.0             0.0                0.0                0.0   \n",
       "1                 0.0             0.0                0.0                0.0   \n",
       "2                 0.0             0.0                0.0                0.0   \n",
       "3                 0.0             0.0                0.0                0.0   \n",
       "4                 0.0             0.0                0.0                0.0   \n",
       "...               ...             ...                ...                ...   \n",
       "45217             0.0             0.0                0.0                0.0   \n",
       "45218             0.0             0.0                0.0                0.0   \n",
       "45219             0.0             0.0                0.0                0.0   \n",
       "45220             0.0             0.0                0.0                0.0   \n",
       "45221             0.0             0.0                0.0                0.0   \n",
       "\n",
       "       ...  native-country_Puerto-Rico  native-country_Scotland  \\\n",
       "0      ...                         0.0                      0.0   \n",
       "1      ...                         0.0                      0.0   \n",
       "2      ...                         0.0                      0.0   \n",
       "3      ...                         0.0                      0.0   \n",
       "4      ...                         0.0                      0.0   \n",
       "...    ...                         ...                      ...   \n",
       "45217  ...                         0.0                      0.0   \n",
       "45218  ...                         0.0                      0.0   \n",
       "45219  ...                         0.0                      0.0   \n",
       "45220  ...                         0.0                      0.0   \n",
       "45221  ...                         0.0                      0.0   \n",
       "\n",
       "       native-country_South  native-country_Taiwan  native-country_Thailand  \\\n",
       "0                       0.0                    0.0                      0.0   \n",
       "1                       0.0                    0.0                      0.0   \n",
       "2                       0.0                    0.0                      0.0   \n",
       "3                       0.0                    0.0                      0.0   \n",
       "4                       0.0                    0.0                      0.0   \n",
       "...                     ...                    ...                      ...   \n",
       "45217                   0.0                    0.0                      0.0   \n",
       "45218                   0.0                    0.0                      0.0   \n",
       "45219                   0.0                    0.0                      0.0   \n",
       "45220                   0.0                    0.0                      0.0   \n",
       "45221                   0.0                    0.0                      0.0   \n",
       "\n",
       "       native-country_Trinadad&Tobago  native-country_United-States  \\\n",
       "0                                 0.0                           1.0   \n",
       "1                                 0.0                           1.0   \n",
       "2                                 0.0                           1.0   \n",
       "3                                 0.0                           1.0   \n",
       "4                                 0.0                           1.0   \n",
       "...                               ...                           ...   \n",
       "45217                             0.0                           1.0   \n",
       "45218                             0.0                           1.0   \n",
       "45219                             0.0                           1.0   \n",
       "45220                             0.0                           1.0   \n",
       "45221                             0.0                           1.0   \n",
       "\n",
       "       native-country_Vietnam  native-country_Yugoslavia  income_>50K  \n",
       "0                         0.0                        0.0          0.0  \n",
       "1                         0.0                        0.0          0.0  \n",
       "2                         0.0                        0.0          1.0  \n",
       "3                         0.0                        0.0          1.0  \n",
       "4                         0.0                        0.0          0.0  \n",
       "...                       ...                        ...          ...  \n",
       "45217                     0.0                        0.0          0.0  \n",
       "45218                     0.0                        0.0          1.0  \n",
       "45219                     0.0                        0.0          0.0  \n",
       "45220                     0.0                        0.0          0.0  \n",
       "45221                     0.0                        0.0          1.0  \n",
       "\n",
       "[45222 rows x 91 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = df.select_dtypes(include=['int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  educational-num  capital-gain  capital-loss  hours-per-week\n",
       "0       25                7             0             0              40\n",
       "1       38                9             0             0              50\n",
       "2       28               12             0             0              40\n",
       "3       44               10          7688             0              40\n",
       "5       34                6             0             0              30\n",
       "...    ...              ...           ...           ...             ...\n",
       "48837   27               12             0             0              38\n",
       "48838   40                9             0             0              40\n",
       "48839   58                9             0             0              40\n",
       "48840   22                9             0             0              20\n",
       "48841   52                9         15024             0              40\n",
       "\n",
       "[45222 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "num_df = pd.DataFrame(scaler.fit_transform(num), \n",
    "                      columns = num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.024983</td>\n",
       "      <td>-1.221559</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.041455</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>0.754701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.798015</td>\n",
       "      <td>0.737034</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.412481</td>\n",
       "      <td>-0.046403</td>\n",
       "      <td>0.877467</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.344079</td>\n",
       "      <td>-1.613277</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.910942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  educational-num  capital-gain  capital-loss  hours-per-week\n",
       "0 -1.024983        -1.221559     -0.146733      -0.21878       -0.078120\n",
       "1 -0.041455        -0.438122     -0.146733      -0.21878        0.754701\n",
       "2 -0.798015         0.737034     -0.146733      -0.21878       -0.078120\n",
       "3  0.412481        -0.046403      0.877467      -0.21878       -0.078120\n",
       "4 -0.344079        -1.613277     -0.146733      -0.21878       -0.910942"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([num_df, cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.024983</td>\n",
       "      <td>-1.221559</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.041455</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.798015</td>\n",
       "      <td>0.737034</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.412481</td>\n",
       "      <td>-0.046403</td>\n",
       "      <td>0.877467</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.344079</td>\n",
       "      <td>-1.613277</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.910942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45217</th>\n",
       "      <td>-0.873671</td>\n",
       "      <td>0.737034</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.244684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45218</th>\n",
       "      <td>0.109857</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45219</th>\n",
       "      <td>1.471665</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45220</th>\n",
       "      <td>-1.251951</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-1.743763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45221</th>\n",
       "      <td>1.017729</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>1.854773</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  educational-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0     -1.024983        -1.221559     -0.146733      -0.21878       -0.078120   \n",
       "1     -0.041455        -0.438122     -0.146733      -0.21878        0.754701   \n",
       "2     -0.798015         0.737034     -0.146733      -0.21878       -0.078120   \n",
       "3      0.412481        -0.046403      0.877467      -0.21878       -0.078120   \n",
       "4     -0.344079        -1.613277     -0.146733      -0.21878       -0.910942   \n",
       "...         ...              ...           ...           ...             ...   \n",
       "45217 -0.873671         0.737034     -0.146733      -0.21878       -0.244684   \n",
       "45218  0.109857        -0.438122     -0.146733      -0.21878       -0.078120   \n",
       "45219  1.471665        -0.438122     -0.146733      -0.21878       -0.078120   \n",
       "45220 -1.251951        -0.438122     -0.146733      -0.21878       -1.743763   \n",
       "45221  1.017729        -0.438122      1.854773      -0.21878       -0.078120   \n",
       "\n",
       "       workclass_Local-gov  workclass_Private  workclass_Self-emp-inc  \\\n",
       "0                      0.0                1.0                     0.0   \n",
       "1                      0.0                1.0                     0.0   \n",
       "2                      1.0                0.0                     0.0   \n",
       "3                      0.0                1.0                     0.0   \n",
       "4                      0.0                1.0                     0.0   \n",
       "...                    ...                ...                     ...   \n",
       "45217                  0.0                1.0                     0.0   \n",
       "45218                  0.0                1.0                     0.0   \n",
       "45219                  0.0                1.0                     0.0   \n",
       "45220                  0.0                1.0                     0.0   \n",
       "45221                  0.0                0.0                     1.0   \n",
       "\n",
       "       workclass_Self-emp-not-inc  workclass_State-gov  ...  \\\n",
       "0                             0.0                  0.0  ...   \n",
       "1                             0.0                  0.0  ...   \n",
       "2                             0.0                  0.0  ...   \n",
       "3                             0.0                  0.0  ...   \n",
       "4                             0.0                  0.0  ...   \n",
       "...                           ...                  ...  ...   \n",
       "45217                         0.0                  0.0  ...   \n",
       "45218                         0.0                  0.0  ...   \n",
       "45219                         0.0                  0.0  ...   \n",
       "45220                         0.0                  0.0  ...   \n",
       "45221                         0.0                  0.0  ...   \n",
       "\n",
       "       native-country_Puerto-Rico  native-country_Scotland  \\\n",
       "0                             0.0                      0.0   \n",
       "1                             0.0                      0.0   \n",
       "2                             0.0                      0.0   \n",
       "3                             0.0                      0.0   \n",
       "4                             0.0                      0.0   \n",
       "...                           ...                      ...   \n",
       "45217                         0.0                      0.0   \n",
       "45218                         0.0                      0.0   \n",
       "45219                         0.0                      0.0   \n",
       "45220                         0.0                      0.0   \n",
       "45221                         0.0                      0.0   \n",
       "\n",
       "       native-country_South  native-country_Taiwan  native-country_Thailand  \\\n",
       "0                       0.0                    0.0                      0.0   \n",
       "1                       0.0                    0.0                      0.0   \n",
       "2                       0.0                    0.0                      0.0   \n",
       "3                       0.0                    0.0                      0.0   \n",
       "4                       0.0                    0.0                      0.0   \n",
       "...                     ...                    ...                      ...   \n",
       "45217                   0.0                    0.0                      0.0   \n",
       "45218                   0.0                    0.0                      0.0   \n",
       "45219                   0.0                    0.0                      0.0   \n",
       "45220                   0.0                    0.0                      0.0   \n",
       "45221                   0.0                    0.0                      0.0   \n",
       "\n",
       "       native-country_Trinadad&Tobago  native-country_United-States  \\\n",
       "0                                 0.0                           1.0   \n",
       "1                                 0.0                           1.0   \n",
       "2                                 0.0                           1.0   \n",
       "3                                 0.0                           1.0   \n",
       "4                                 0.0                           1.0   \n",
       "...                               ...                           ...   \n",
       "45217                             0.0                           1.0   \n",
       "45218                             0.0                           1.0   \n",
       "45219                             0.0                           1.0   \n",
       "45220                             0.0                           1.0   \n",
       "45221                             0.0                           1.0   \n",
       "\n",
       "       native-country_Vietnam  native-country_Yugoslavia  income_>50K  \n",
       "0                         0.0                        0.0          0.0  \n",
       "1                         0.0                        0.0          0.0  \n",
       "2                         0.0                        0.0          1.0  \n",
       "3                         0.0                        0.0          1.0  \n",
       "4                         0.0                        0.0          0.0  \n",
       "...                       ...                        ...          ...  \n",
       "45217                     0.0                        0.0          0.0  \n",
       "45218                     0.0                        0.0          1.0  \n",
       "45219                     0.0                        0.0          0.0  \n",
       "45220                     0.0                        0.0          0.0  \n",
       "45221                     0.0                        0.0          1.0  \n",
       "\n",
       "[45222 rows x 96 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = new_df.drop('income_>50K',axis=1)\n",
    "Y = new_df.pop('income_>50K')\n",
    "X = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=.30,random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = lr.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8499299771504386"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy classification score.\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9477,  683],\n",
       "       [1353, 2054]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.93      0.90     10160\n",
      "         1.0       0.75      0.60      0.67      3407\n",
      "\n",
      "    accuracy                           0.85     13567\n",
      "   macro avg       0.81      0.77      0.79     13567\n",
      "weighted avg       0.84      0.85      0.84     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 l1_ratio=None, max_iter=100,\n",
       "                                 multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                                 random_state=None, solver='lbfgs', tol=0.0001,\n",
       "                                 verbose=0, warm_start=False),\n",
       "    n_features_to_select=30, step=1, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "lr_temp = LogisticRegression()\n",
    "## No. of features taking = 30\n",
    "rfe = RFE(lr_temp, 30)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Included</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>educational-num</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capital-gain</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital-loss</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hours-per-week</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>native-country_Thailand</td>\n",
       "      <td>False</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>native-country_Trinadad&amp;Tobago</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>native-country_United-States</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>native-country_Vietnam</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>native-country_Yugoslavia</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Columns  Included  Ranking\n",
       "0                              age     False       18\n",
       "1                  educational-num      True        1\n",
       "2                     capital-gain      True        1\n",
       "3                     capital-loss     False       32\n",
       "4                   hours-per-week     False       19\n",
       "..                             ...       ...      ...\n",
       "90         native-country_Thailand     False       41\n",
       "91  native-country_Trinadad&Tobago     False       47\n",
       "92    native-country_United-States     False        5\n",
       "93          native-country_Vietnam      True        1\n",
       "94       native-country_Yugoslavia     False       27\n",
       "\n",
       "[95 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.DataFrame({'Columns' : X_train.columns, 'Included' : rfe.support_, 'Ranking' : rfe.ranking_})\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['educational-num', 'capital-gain', 'workclass_Without-pay',\n",
       "       'education_1st-4th', 'education_5th-6th', 'education_Prof-school',\n",
       "       'marital-status_Married-AF-spouse', 'marital-status_Married-civ-spouse',\n",
       "       'occupation_Exec-managerial', 'occupation_Farming-fishing',\n",
       "       'occupation_Handlers-cleaners', 'occupation_Other-service',\n",
       "       'occupation_Priv-house-serv', 'relationship_Other-relative',\n",
       "       'relationship_Own-child', 'relationship_Wife', 'gender_Male',\n",
       "       'native-country_Canada', 'native-country_Columbia',\n",
       "       'native-country_Cuba', 'native-country_Dominican-Republic',\n",
       "       'native-country_Ireland', 'native-country_Italy', 'native-country_Laos',\n",
       "       'native-country_Nicaragua', 'native-country_Outlying-US(Guam-USVI-etc)',\n",
       "       'native-country_Peru', 'native-country_Philippines',\n",
       "       'native-country_South', 'native-country_Vietnam'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_col = X_train.columns[rfe.support_]\n",
    "imp_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>workclass_Without-pay</th>\n",
       "      <th>education_1st-4th</th>\n",
       "      <th>education_5th-6th</th>\n",
       "      <th>education_Prof-school</th>\n",
       "      <th>marital-status_Married-AF-spouse</th>\n",
       "      <th>marital-status_Married-civ-spouse</th>\n",
       "      <th>occupation_Exec-managerial</th>\n",
       "      <th>occupation_Farming-fishing</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Dominican-Republic</th>\n",
       "      <th>native-country_Ireland</th>\n",
       "      <th>native-country_Italy</th>\n",
       "      <th>native-country_Laos</th>\n",
       "      <th>native-country_Nicaragua</th>\n",
       "      <th>native-country_Outlying-US(Guam-USVI-etc)</th>\n",
       "      <th>native-country_Peru</th>\n",
       "      <th>native-country_Philippines</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21220</th>\n",
       "      <td>-1.613277</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8492</th>\n",
       "      <td>1.128753</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22673</th>\n",
       "      <td>-0.046403</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1.128753</td>\n",
       "      <td>0.166868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34307</th>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35702</th>\n",
       "      <td>-0.046403</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26767</th>\n",
       "      <td>-0.046403</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>1.912190</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24894</th>\n",
       "      <td>1.128753</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29828</th>\n",
       "      <td>-1.613277</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31655 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       educational-num  capital-gain  workclass_Without-pay  \\\n",
       "21220        -1.613277     -0.146733                    0.0   \n",
       "8492          1.128753     -0.146733                    0.0   \n",
       "22673        -0.046403     -0.146733                    0.0   \n",
       "755           1.128753      0.166868                    0.0   \n",
       "34307        -0.438122     -0.146733                    0.0   \n",
       "...                ...           ...                    ...   \n",
       "35702        -0.046403     -0.146733                    0.0   \n",
       "26767        -0.046403     -0.146733                    0.0   \n",
       "6618          1.912190     -0.146733                    0.0   \n",
       "24894         1.128753     -0.146733                    0.0   \n",
       "29828        -1.613277     -0.146733                    0.0   \n",
       "\n",
       "       education_1st-4th  education_5th-6th  education_Prof-school  \\\n",
       "21220                0.0                0.0                    0.0   \n",
       "8492                 0.0                0.0                    0.0   \n",
       "22673                0.0                0.0                    0.0   \n",
       "755                  0.0                0.0                    0.0   \n",
       "34307                0.0                0.0                    0.0   \n",
       "...                  ...                ...                    ...   \n",
       "35702                0.0                0.0                    0.0   \n",
       "26767                0.0                0.0                    0.0   \n",
       "6618                 0.0                0.0                    1.0   \n",
       "24894                0.0                0.0                    0.0   \n",
       "29828                0.0                0.0                    0.0   \n",
       "\n",
       "       marital-status_Married-AF-spouse  marital-status_Married-civ-spouse  \\\n",
       "21220                               0.0                                1.0   \n",
       "8492                                0.0                                1.0   \n",
       "22673                               0.0                                0.0   \n",
       "755                                 0.0                                0.0   \n",
       "34307                               0.0                                0.0   \n",
       "...                                 ...                                ...   \n",
       "35702                               0.0                                0.0   \n",
       "26767                               0.0                                0.0   \n",
       "6618                                0.0                                0.0   \n",
       "24894                               0.0                                1.0   \n",
       "29828                               0.0                                0.0   \n",
       "\n",
       "       occupation_Exec-managerial  occupation_Farming-fishing  ...  \\\n",
       "21220                         0.0                         0.0  ...   \n",
       "8492                          0.0                         0.0  ...   \n",
       "22673                         0.0                         0.0  ...   \n",
       "755                           0.0                         0.0  ...   \n",
       "34307                         0.0                         0.0  ...   \n",
       "...                           ...                         ...  ...   \n",
       "35702                         0.0                         0.0  ...   \n",
       "26767                         0.0                         0.0  ...   \n",
       "6618                          0.0                         0.0  ...   \n",
       "24894                         1.0                         0.0  ...   \n",
       "29828                         0.0                         0.0  ...   \n",
       "\n",
       "       native-country_Dominican-Republic  native-country_Ireland  \\\n",
       "21220                                0.0                     0.0   \n",
       "8492                                 0.0                     0.0   \n",
       "22673                                0.0                     0.0   \n",
       "755                                  0.0                     0.0   \n",
       "34307                                0.0                     0.0   \n",
       "...                                  ...                     ...   \n",
       "35702                                0.0                     0.0   \n",
       "26767                                0.0                     0.0   \n",
       "6618                                 0.0                     0.0   \n",
       "24894                                0.0                     0.0   \n",
       "29828                                0.0                     0.0   \n",
       "\n",
       "       native-country_Italy  native-country_Laos  native-country_Nicaragua  \\\n",
       "21220                   0.0                  0.0                       0.0   \n",
       "8492                    0.0                  0.0                       0.0   \n",
       "22673                   0.0                  0.0                       0.0   \n",
       "755                     0.0                  0.0                       0.0   \n",
       "34307                   0.0                  0.0                       0.0   \n",
       "...                     ...                  ...                       ...   \n",
       "35702                   0.0                  0.0                       0.0   \n",
       "26767                   0.0                  0.0                       0.0   \n",
       "6618                    0.0                  0.0                       0.0   \n",
       "24894                   0.0                  0.0                       0.0   \n",
       "29828                   0.0                  0.0                       0.0   \n",
       "\n",
       "       native-country_Outlying-US(Guam-USVI-etc)  native-country_Peru  \\\n",
       "21220                                        0.0                  0.0   \n",
       "8492                                         0.0                  0.0   \n",
       "22673                                        0.0                  0.0   \n",
       "755                                          0.0                  0.0   \n",
       "34307                                        0.0                  0.0   \n",
       "...                                          ...                  ...   \n",
       "35702                                        0.0                  0.0   \n",
       "26767                                        0.0                  0.0   \n",
       "6618                                         0.0                  0.0   \n",
       "24894                                        0.0                  0.0   \n",
       "29828                                        0.0                  0.0   \n",
       "\n",
       "       native-country_Philippines  native-country_South  \\\n",
       "21220                         0.0                   0.0   \n",
       "8492                          0.0                   0.0   \n",
       "22673                         0.0                   0.0   \n",
       "755                           0.0                   0.0   \n",
       "34307                         0.0                   0.0   \n",
       "...                           ...                   ...   \n",
       "35702                         0.0                   0.0   \n",
       "26767                         0.0                   0.0   \n",
       "6618                          0.0                   0.0   \n",
       "24894                         0.0                   0.0   \n",
       "29828                         0.0                   0.0   \n",
       "\n",
       "       native-country_Vietnam  \n",
       "21220                     0.0  \n",
       "8492                      0.0  \n",
       "22673                     0.0  \n",
       "755                       0.0  \n",
       "34307                     0.0  \n",
       "...                       ...  \n",
       "35702                     0.0  \n",
       "26767                     0.0  \n",
       "6618                      0.0  \n",
       "24894                     0.0  \n",
       "29828                     0.0  \n",
       "\n",
       "[31655 rows x 30 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new = X_train[imp_col]\n",
    "X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=250,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrn = LogisticRegression(max_iter=250)\n",
    "lrn.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_new = lrn.predict(X_train_new)\n",
    "y_predict_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8499299771504386"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17231214, 0.29928058, 0.41859915, 0.52288518, 0.62121152,\n",
       "       0.66781356, 0.69754836, 0.72354624, 0.74943991, 0.77017519,\n",
       "       0.78875128, 0.80669662, 0.8222957 , 0.83642948, 0.84981652,\n",
       "       0.8613533 , 0.87204272, 0.88250789, 0.89196213, 0.90045472,\n",
       "       0.9079432 , 0.91518055, 0.92166351, 0.9276611 , 0.93310102,\n",
       "       0.93814771, 0.94258311, 0.94674013, 0.95079417, 0.95475762,\n",
       "       0.95861136, 0.96208182, 0.96547486, 0.96881006, 0.9718258 ,\n",
       "       0.97417841, 0.97648633, 0.97868178, 0.98059593, 0.98226676,\n",
       "       0.98385806, 0.98536841, 0.98661583, 0.98783116, 0.98894152,\n",
       "       0.98994237, 0.99067315, 0.99131579, 0.99191365, 0.9924472 ,\n",
       "       0.99292544, 0.99335723, 0.99375246, 0.99410984, 0.99446161,\n",
       "       0.99478634, 0.99509617, 0.99538628, 0.99566147, 0.99591763,\n",
       "       0.99617243, 0.9964134 , 0.99664952, 0.99688091, 0.99710149,\n",
       "       0.99731476, 0.99752243, 0.99770572, 0.99788872, 0.99805956,\n",
       "       0.99822186, 0.99837038, 0.99851495, 0.9986505 , 0.99877442,\n",
       "       0.99889489, 0.99901028, 0.99912055, 0.99921634, 0.99930844,\n",
       "       0.99938244, 0.99945457, 0.99952369, 0.9995906 , 0.99965095,\n",
       "       0.99970816, 0.99976168, 0.99981436, 0.99986519, 0.99991398,\n",
       "       0.99996035, 0.99999573, 0.99999845, 1.        , 1.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cummulative variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation :-\n",
    "* Based on the plot above it's clear we should pick 45 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of components = 45\n",
    "pca = PCA(n_components=45)\n",
    "X_PCA = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.61176362e+00,  8.43024424e-02,  1.32257923e-01, ...,\n",
       "        -2.93343872e-02, -1.77468944e-02, -3.67406506e-02],\n",
       "       [ 1.73045645e-01, -6.38398448e-01,  1.78341469e-01, ...,\n",
       "         8.01742981e-04, -1.42455516e-03,  2.36057541e-02],\n",
       "       [ 1.69250217e-01,  7.78385497e-01, -7.04016546e-02, ...,\n",
       "        -1.05172755e-02,  1.80509540e-02,  4.58021072e-03],\n",
       "       ...,\n",
       "       [ 1.76151012e-01, -1.38635020e+00,  3.18449750e-01, ...,\n",
       "        -6.50772449e-03,  8.21825827e-02, -1.31135671e-02],\n",
       "       [-2.12269819e+00,  7.15849333e-01,  2.68697215e-02, ...,\n",
       "        -1.25168173e-02, -4.03085742e-03,  1.06939778e-02],\n",
       "       [ 1.04287139e+00, -7.57058381e-01,  1.43261506e+00, ...,\n",
       "         5.97347616e-03,  2.47255028e-03, -2.25358851e-02]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_PCA[:], Y, test_size=.30, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logist = LogisticRegression(max_iter = 250)\n",
    "logist.fit(x_train,y_train)\n",
    "##Predicting the test data\n",
    "y_predict_logistic = logist.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8504459349893123\n",
      "\n",
      "\n",
      "Confusion metricx :\n",
      "[[9497  663]\n",
      " [1366 2041]]\n",
      "\n",
      "\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.93      0.90     10160\n",
      "         1.0       0.75      0.60      0.67      3407\n",
      "\n",
      "    accuracy                           0.85     13567\n",
      "   macro avg       0.81      0.77      0.79     13567\n",
      "weighted avg       0.84      0.85      0.84     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score : {}'.format(accuracy_score(y_test,y_predict_logistic)))\n",
    "print('\\n')\n",
    "print('Confusion metricx :')\n",
    "print(confusion_matrix(y_test,y_predict_logistic))\n",
    "print('\\n')\n",
    "print('Classification Report :')\n",
    "print(classification_report(y_test,y_predict_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = svm.SVC()\n",
    "svm.fit(x_train,y_train)\n",
    "##Predicting the test data\n",
    "y_predict_svm = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8544998894376059\n",
      "\n",
      "\n",
      "Confusion metricx :\n",
      "[[9581  579]\n",
      " [1395 2012]]\n",
      "\n",
      "\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.94      0.91     10160\n",
      "         1.0       0.78      0.59      0.67      3407\n",
      "\n",
      "    accuracy                           0.85     13567\n",
      "   macro avg       0.82      0.77      0.79     13567\n",
      "weighted avg       0.85      0.85      0.85     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score : {}'.format(accuracy_score(y_test,y_predict_svm)))\n",
    "print('\\n')\n",
    "print('Confusion metricx :')\n",
    "print(confusion_matrix(y_test,y_predict_svm))\n",
    "print('\\n')\n",
    "print('Classification Report :')\n",
    "print(classification_report(y_test,y_predict_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train,y_train)\n",
    "##Predicting the test data\n",
    "y_predict_knn = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8262696248249429\n",
      "\n",
      "\n",
      "Confusion metricx :\n",
      "[[9141 1019]\n",
      " [1338 2069]]\n",
      "\n",
      "\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.90      0.89     10160\n",
      "         1.0       0.67      0.61      0.64      3407\n",
      "\n",
      "    accuracy                           0.83     13567\n",
      "   macro avg       0.77      0.75      0.76     13567\n",
      "weighted avg       0.82      0.83      0.82     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score : {}'.format(accuracy_score(y_test,y_predict_knn)))\n",
    "print('\\n')\n",
    "print('Confusion metricx :')\n",
    "print(confusion_matrix(y_test,y_predict_knn))\n",
    "print('\\n')\n",
    "print('Classification Report :')\n",
    "print(classification_report(y_test,y_predict_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train,y_train)\n",
    "##Predicting the test data\n",
    "y_predict_dtc = dtc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8034200633891059\n",
      "\n",
      "\n",
      "Confusion metricx :\n",
      "[[8903 1257]\n",
      " [1410 1997]]\n",
      "\n",
      "\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.88      0.87     10160\n",
      "         1.0       0.61      0.59      0.60      3407\n",
      "\n",
      "    accuracy                           0.80     13567\n",
      "   macro avg       0.74      0.73      0.73     13567\n",
      "weighted avg       0.80      0.80      0.80     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score : {}'.format(accuracy_score(y_test,y_predict_dtc)))\n",
    "print('\\n')\n",
    "print('Confusion metricx :')\n",
    "print(confusion_matrix(y_test,y_predict_dtc))\n",
    "print('\\n')\n",
    "print('Classification Report :')\n",
    "print(classification_report(y_test,y_predict_dtc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
